{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Houston Holman\n",
        "2/22/23\n",
        "\n",
        "WordNet Showcase"
      ],
      "metadata": {
        "id": "rTz4GgWMKilG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet is a large lexical database of words in the English language. Each word is assigned one or more synsets which are collections of words that are very similar to the target word. WordNet is used in natural language processing in order to help the computer to understand the meaning of words."
      ],
      "metadata": {
        "id": "45bAPDSlKur0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "y89A6oL8ML-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "c6EBqVWjMN-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn"
      ],
      "metadata": {
        "id": "lq2uKaLLLeGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are all the synsets for the word \"dog\""
      ],
      "metadata": {
        "id": "-8e36p2CN7yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('dog')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjKHdLjpN_Dv",
        "outputId": "bf3bafd3-18b1-43bb-9bff-7dbf3eadea91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('dog.n.01'),\n",
              " Synset('frump.n.01'),\n",
              " Synset('dog.n.03'),\n",
              " Synset('cad.n.01'),\n",
              " Synset('frank.n.02'),\n",
              " Synset('pawl.n.01'),\n",
              " Synset('andiron.n.01'),\n",
              " Synset('chase.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the definition, usage example, and lemmas of 'dog.n.03'"
      ],
      "metadata": {
        "id": "JYzN6ycZOEem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dog.n.03').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TM_giE2MOHVE",
        "outputId": "236c8e35-18e4-4875-cbd0-c13a890fa7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'informal term for a man'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dog.n.03').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLTcQaEYON11",
        "outputId": "bd5b1cc7-0b78-4e26-9660-0197a6081414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you lucky dog']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dog.n.03').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKkou6dmOS2J",
        "outputId": "70974148-f941-4da8-da67-d8ddf3b18ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('dog.n.03.dog')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's traverse the hierarchy for 'dog.n.03'"
      ],
      "metadata": {
        "id": "pSRgbh2UO7aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyp = wn.synset('dog.n.03').hypernyms()[0]\n",
        "top = wn.synset('entity.n.01')\n",
        "while hyp:\n",
        "    print(hyp)\n",
        "    if hyp == top:\n",
        "        break\n",
        "    if hyp.hypernyms():\n",
        "        hyp = hyp.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh28giImO_6H",
        "outputId": "6ca8611a-0198-4a43-f1f0-6e7df68b4aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('chap.n.01')\n",
            "Synset('male.n.02')\n",
            "Synset('person.n.01')\n",
            "Synset('causal_agent.n.01')\n",
            "Synset('physical_entity.n.01')\n",
            "Synset('entity.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet's organization of nouns is interesting. In this example, I find it a bit strange that 'dog' does not lead directly into 'male' and instead first goes to 'chap'. I am also not sure what a 'casual_agent' is. Other than those oddities, the hierarchy makes sense."
      ],
      "metadata": {
        "id": "r3e0IqS3PPHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dog.n.03').hypernyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwppbb6rPwRy",
        "outputId": "c58e3c2b-61bb-4f4c-f379-56ad5d0c5233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('chap.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dog.n.03').hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny1dcwohP1mj",
        "outputId": "50201014-339d-486a-b6e8-1ebb5958698e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dog.n.03').part_meronyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9iOTG_0P7aW",
        "outputId": "5523e0a2-2fc3-4bfd-ad43-7c25e2bdbe07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dog.n.03').part_holonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_4uBwRZQOFp",
        "outputId": "9b2e482e-4cf1-496c-c874-4febb14b8d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for lemma in wn.synset('dog.n.03').lemmas():\n",
        "  print(lemma.antonyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4wnO8wGQWT3",
        "outputId": "fceaad3c-a616-4ff1-f6e1-4f6a22b6a961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are all the synsets for the word \"pen\""
      ],
      "metadata": {
        "id": "LzflI6KgLuii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('pen')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dujsugDeLqBB",
        "outputId": "b22ed56f-7b12-48f5-edb9-5aebd876251b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Synset('pen.n.01')"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the definition, usage example, and lemmas of 'write.v.01'"
      ],
      "metadata": {
        "id": "Obw-1yfONBM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('write.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hj-u3ERzNJ38",
        "outputId": "b47398db-bae0-4dad-f210-35a25cee766e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'produce a literary work'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('write.v.01').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhggGtcLNfE3",
        "outputId": "ab57ec48-e241-4144-bc72-b2bbd3c8a2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['She composed a poem', 'He wrote four novels']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('write.v.01').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uDwK2BlNgMe",
        "outputId": "2f9baafe-4b39-4364-b84a-ce420488e831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('write.v.01.write'),\n",
              " Lemma('write.v.01.compose'),\n",
              " Lemma('write.v.01.pen'),\n",
              " Lemma('write.v.01.indite')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's traverse the hierarchy for 'write.v.01'"
      ],
      "metadata": {
        "id": "VrBVo_YVRQVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyp = wn.synset('write.v.01').hypernyms()[0]\n",
        "i = 0\n",
        "while i < 5:\n",
        "    i = i+1\n",
        "    print(hyp)\n",
        "    if hyp.hypernyms():\n",
        "        hyp = hyp.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "006EZ9VfRT9E",
        "outputId": "dfd72c52-ed78-4484-85a1-f7ebcb68e9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('create_verbally.v.01')\n",
            "Synset('make.v.03')\n",
            "Synset('make.v.03')\n",
            "Synset('make.v.03')\n",
            "Synset('make.v.03')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet's hierarchy of this verb confuses me. It surprises me that it only consists of 3 levels but I guess that makes sense since I am having a hard time imagining what goes above 'make'. I have no idea how 'write' becomes 'create_verbally', considering that there is nothing verbal about it. I would have assumed it would lead into 'create'."
      ],
      "metadata": {
        "id": "mYSRudONRyfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use morphy() to show that other forms of the word share the same base"
      ],
      "metadata": {
        "id": "Nlw-djTlT6sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('penned', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xE6ykZCvSXwB",
        "outputId": "4ba3577d-f2ad-455f-d658-4453852dced5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('penning', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9K0puSvdUCtA",
        "outputId": "115d02f2-066f-455d-d3c9-d0a07fa2e5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now test the similarity between two words. For this example, let's use the words 'planet' and 'moon'"
      ],
      "metadata": {
        "id": "aLriEl7XURQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planet = wn.synset('planet.n.01')\n",
        "planet.definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ikeQD45LUcoO",
        "outputId": "0b32c38f-cbf7-453f-ff11-88fe908de32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(astronomy) any of the nine large celestial bodies in the solar system that revolve around the sun and shine by reflected light; Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto in order of their proximity to the sun; viewed from the constellation Hercules, all the planets rotate around the sun in a counterclockwise direction'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "moon = wn.synset('moon.n.01')\n",
        "moon.definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "445G0FR8Upx3",
        "outputId": "49e026e2-e7d3-4210-9434-2b6b7b52e047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the natural satellite of the Earth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.wup_similarity(planet,moon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnjScrftU9f7",
        "outputId": "9e236300-009b-4f56-d300-dae7cd7218c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use the lesk algorithm to see if it can accurately pick out the correct synsets"
      ],
      "metadata": {
        "id": "iBXRpwuHfNUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "\n",
        "context = \"Each planet in the solar system may have a moon that orbits it.\"\n",
        "context_tokens = nltk.word_tokenize(context)\n",
        "print(lesk(context_tokens, 'planet'))\n",
        "print(lesk(context_tokens, 'moon'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjCzeTPYYL1S",
        "outputId": "fbd2c032-ec00-4bc2-e17b-efce8e921ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('planet.n.01')\n",
            "Synset('moon.v.02')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synset('planet.n.01').definition())\n",
        "print(wn.synset('moon.v.02').definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC8jwpUqe5I4",
        "outputId": "b88af4d9-6d8c-4658-951a-87ca9dd9b010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(astronomy) any of the nine large celestial bodies in the solar system that revolve around the sun and shine by reflected light; Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto in order of their proximity to the sun; viewed from the constellation Hercules, all the planets rotate around the sun in a counterclockwise direction\n",
            "be idle in a listless or dreamy way\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Wu-Palmer algorithm seems to be very accurate in determining the similarity between 'planet' and 'moon'. My guess is that both belong to some kind of 'celestial objects' category, which explains their high similarity score. The Lesk algorithm was able to accurately pick out the correct synset for 'planet' but failed to find the correct synset for 'moon'. This shows that the algorithm is not perfect and can miss things."
      ],
      "metadata": {
        "id": "VgV7fpvmfIBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet is a tool that assigns sentiment scores to words based on their meanings. When given a word, it returns how negative, neutral, or positive that word is. Using this information, SentiWordNet can be used to classify text or judge opinions."
      ],
      "metadata": {
        "id": "Iv4v__cAhHKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "word = swn.senti_synset('assault.n.02')\n",
        "print(\"Positive score = \", word.pos_score())\n",
        "print(\"Negative score = \", word.neg_score())\n",
        "print(\"Objective score = \", word.obj_score())"
      ],
      "metadata": {
        "id": "KAoUsidoh0k3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2d7c95-e06e-4955-ca6a-1f5367390aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive score =  0.0\n",
            "Negative score =  0.375\n",
            "Objective score =  0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The ravenous child murdered the bowl of delicious cereal\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "for token in tokens:\n",
        "  if len(wn.synsets(token)) > 0:\n",
        "    synset = wn.synsets(token)[0]\n",
        "    word = swn.senti_synset(synset.name())\n",
        "    print(\"Word: \" + token)\n",
        "    print(\"Positive score = \", word.pos_score())\n",
        "    print(\"Negative score = \", word.neg_score())\n",
        "    print(\"Objective score = \", word.obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIPJpymejBm5",
        "outputId": "7523ed29-63f6-45ef-d900-43ec50813351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: ravenous\n",
            "Positive score =  0.25\n",
            "Negative score =  0.625\n",
            "Objective score =  0.125\n",
            "Word: child\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "Word: murdered\n",
            "Positive score =  0.0\n",
            "Negative score =  0.625\n",
            "Objective score =  0.375\n",
            "Word: bowl\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "Word: delicious\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "Word: cereal\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that SentiWordNet does an alright job at sentiment analysis. It seems to catch most of the obvious words, but it does miss a lot. It surprised me that 'assault' was considered mostly neutral and only patially negative. In the sentence example, most of the results make sense. I was surprised to find that ravenous is considered mostly negative but also somewhat positive. I am wondering why delicious is not considered a positive word. Regardless, these scores can be used in NLP programs to perform sentiment analysis. This can be especially useful for analyzing opinions on certain topics by looking at social medias like Twitter."
      ],
      "metadata": {
        "id": "0u3oBkoSz7xD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocation refers to the tendency for some words to occur together more often than chance, insinuating that there is a relationship between those words. This is important in NLP because it can be used to analyze meaningful patterns in texts. "
      ],
      "metadata": {
        "id": "i0EKlp8h1LiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "nltk.download('inaugural')\n",
        "\n",
        "from nltk.book import text4\n",
        "\n",
        "print(text4.collocations())\n",
        "\n",
        "text = ' '.join(text4.tokens)\n",
        "\n",
        "vocab = len(set(text4))\n",
        "hg = text.count('fellow Americans')/vocab\n",
        "print(\"p(fellow Americans) = \",hg )\n",
        "h = text.count('fellow')/vocab\n",
        "print(\"p(fellow) = \", h)\n",
        "g = text.count('Americans')/vocab\n",
        "print('p(Americans) = ', g)\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J2w7HPDk5CpM",
        "outputId": "b4eb2ce2-828b-4480-af4a-b6f8e0c0d2ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n",
            "None\n",
            "p(fellow Americans) =  0.00199501246882793\n",
            "p(fellow) =  0.013665835411471322\n",
            "p(Americans) =  0.008478802992518703\n",
            "pmi =  4.105819692018779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the mutual information formula returned a positive number, that means that 'fellow Americans' is likely to be a collocation."
      ],
      "metadata": {
        "id": "ldcWufSvZGse"
      }
    }
  ]
}